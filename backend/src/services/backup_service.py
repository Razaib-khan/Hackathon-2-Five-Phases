import os
import shutil
import zipfile
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Optional
import logging
from sqlalchemy import text
from sqlalchemy.orm import Session

from ..config.settings import settings


class BackupService:
    @staticmethod
    def create_backup(db: Session, backup_type: str = "full") -> str:
        """
        Create a database backup
        """
        backup_dir = Path(settings.BACKUP_DIR) if hasattr(settings, 'BACKUP_DIR') else Path("./backups")
        backup_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_filename = f"hackathon_platform_backup_{backup_type}_{timestamp}.sql"
        backup_path = backup_dir / backup_filename

        try:
            # This would typically use pg_dump for PostgreSQL or similar tools
            # For now, we'll simulate the backup process
            with open(backup_path, 'w') as backup_file:
                backup_file.write(f"-- Backup of Hackathon Platform Database\n")
                backup_file.write(f"-- Backup Type: {backup_type}\n")
                backup_file.write(f"-- Timestamp: {datetime.now()}\n")
                backup_file.write(f"-- Generated by: BackupService\n\n")

                # In a real implementation, we would dump the actual database content
                backup_file.write("-- Actual database content would be dumped here\n")

            logging.info(f"Backup created successfully: {backup_path}")
            return str(backup_path)

        except Exception as e:
            logging.error(f"Error creating backup: {str(e)}")
            raise e

    @staticmethod
    def schedule_regular_backups():
        """
        Schedule regular backups (this would typically be handled by cron or similar)
        """
        # In a real implementation, this would schedule backups
        # For now, we'll just return the schedule
        return {
            "daily_backup": "2:00 AM",
            "weekly_backup": "Sunday 1:00 AM",
            "monthly_backup": "1st of month 3:00 AM"
        }

    @staticmethod
    def get_retention_policy() -> dict:
        """
        Get the data retention policy
        """
        return {
            "user_accounts": "Indefinite (until user requests deletion)",
            "audit_logs": "7 years for legal compliance",
            "notifications": "1 year",
            "submissions": "2 years after hackathon completion",
            "evaluation_data": "5 years for academic/review purposes",
            "backup_files": "6 months for recovery purposes",
            "temporary_files": "24 hours",
            "session_data": "30 days after last activity"
        }

    @staticmethod
    def cleanup_old_data(db: Session):
        """
        Clean up data that exceeds retention limits
        """
        from ..models.user import User
        from ..models.audit_log import AuditLog
        from ..models.notification import Notification
        from ..models.submission import Submission

        current_time = datetime.utcnow()

        # Clean up old notifications (older than 1 year)
        one_year_ago = current_time - timedelta(days=365)
        old_notifications = db.query(Notification).filter(
            Notification.sent_at < one_year_ago
        ).all()

        for notification in old_notifications:
            db.delete(notification)

        # Clean up old audit logs (older than 7 years, keeping only recent ones)
        seven_years_ago = current_time - timedelta(days=7*365)
        old_audit_logs = db.query(AuditLog).filter(
            AuditLog.timestamp < seven_years_ago
        ).all()

        for audit_log in old_audit_logs:
            db.delete(audit_log)

        db.commit()
        logging.info(f"Cleaned up {len(old_notifications)} old notifications and {len(old_audit_logs)} old audit logs")

    @staticmethod
    def get_backup_history() -> List[dict]:
        """
        Get the history of backups
        """
        backup_dir = Path(settings.BACKUP_DIR) if hasattr(settings, 'BACKUP_DIR') else Path("./backups")

        if not backup_dir.exists():
            return []

        backups = []
        for backup_file in backup_dir.glob("*.sql"):
            stat = backup_file.stat()
            backups.append({
                "filename": backup_file.name,
                "size": stat.st_size,
                "created_at": datetime.fromtimestamp(stat.st_mtime),
                "path": str(backup_file)
            })

        # Sort by creation time, newest first
        backups.sort(key=lambda x: x["created_at"], reverse=True)
        return backups

    @staticmethod
    def restore_backup(backup_path: str, db: Session):
        """
        Restore a database from backup
        """
        # In a real implementation, this would restore from the backup file
        # For security reasons, this is typically done outside the application
        raise NotImplementedError("Restore functionality is not implemented for security reasons. Please restore using database tools directly.")

    @staticmethod
    def validate_backup_integrity(backup_path: str) -> bool:
        """
        Validate that a backup file is not corrupted
        """
        try:
            if not os.path.exists(backup_path):
                return False

            # Check file size (should not be empty)
            if os.path.getsize(backup_path) == 0:
                return False

            # In a real implementation, we would perform more thorough checks
            # like verifying checksums or attempting to parse the SQL
            return True
        except Exception:
            return False